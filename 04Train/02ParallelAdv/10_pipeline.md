<!--Copyright ¬© ZOMI ÈÄÇÁî®‰∫é[License](https://github.com/Infrasys-AI/AIInfra)ÁâàÊùÉËÆ∏ÂèØ-->

# ÊµÅÊ∞¥Âπ∂Ë°å1F1B/1F1B InterleavedÂéüÁêÜ

abstractÔºöÂÖàÂâç‰ªãÁªçÁöÑGpipeÂ≠òÂú®Á°¨‰ª∂Âà©Áî®Áéá‰ΩéÔºåÂä®ÊÄÅÂÜÖÂ≠òÂéãÂäõÂ§ßÁöÑÈóÆÈ¢òÔºåÊú¨ÁØá‰ªãÁªçÊñ∞ÁöÑÊµÅÊ∞¥Á∫øÊäÄÊúØÊù•ËßÑÈÅø

## PipeDreamÂü∫Êú¨ÂéüÁêÜ

ÂõûÈ°æ‰∏Ä‰∏ãGpipeÊµÅÊ∞¥Âπ∂Ë°åÂ≠òÂú®Âä®ÊÄÅÂ≥∞ÂÄºÂÜÖÂ≠òÂ§ßÁöÑÈóÆÈ¢òÔºåÂ¶ÇÂõæÊâÄÁ§∫ÔºöËã•ËæìÂÖ•batchË¢´ÂàíÂàÜ‰∏∫n‰∏™micro-batchÔºåÂàôÂØπ‰∫é‰ªªÊÑèdeviceÔºåÈúÄË¶ÅÁºìÂ≠òn‰ªΩÂâçÂêëÊøÄÊ¥ªÂÄºÔºàÂõæ‰∏≠n=8Ôºâ.

![GpipelineÂéüÁêÜ](images/10pipeline01.png)

PipeDreamÊµÅÊ∞¥Á∫øÂπ∂Ë°åÈááÂèñ‰∫Ü**1FIB**ÁöÑÁ≠ñÁï•ÔºåÂæàÂ•ΩÁöÑËßÑÈÅø‰∫ÜÁ°¨‰ª∂ÂÜÖÂ≠òÊúâÈôêÁöÑÈóÆÈ¢ò„ÄÇ

Âú®ÊµÅÊ∞¥Á∫øÂπ∂Ë°åÔºàpipeline parallelÔºâ‰∏≠ÔºåÊØèÊ¨°ÂâçÂêëËÆ°ÁÆó‰∫ßÁîüÁöÑ activation Âè™ÊúâÂú®ÂØπÂ∫îÁöÑÂèçÂêëËÆ°ÁÆóÂÆåÊàê‰πãÂêéÊâçËÉΩÈáäÊîæÔºàÂç≥‰Ωø‰ΩøÁî®‰∫Ü Checkpointing ÊäÄÊúØÔºâ„ÄÇÂõ†Ê≠§ÔºåË¶ÅÂ∞ΩÂèØËÉΩÂú∞ËäÇÁúÅ activation Âç†Áî®ÁöÑÊòæÂ≠òÔºåÂ∞±ÈúÄË¶ÅÂ∞ΩÈáèÁº©Áü≠ÊØè‰ªΩ activation Âú®ÂÜÖÂ≠ò‰∏≠ÂÅúÁïôÁöÑÊó∂Èó¥Ôºå‰πüÂ∞±ÊòØËÆ©ÂÆÉ‰ª¨Â∞ΩÊó©Ë¢´ÈáäÊîæ„ÄÇË¶ÅÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºåÂÖ≥ÈîÆ‰æøÊòØËÆ©ÊØèmicro-batch ÁöÑÂèçÂêëËÆ°ÁÆóÂ∞ΩÊó©ÂºÄÂßãÂπ∂ÂÆåÊàê„ÄÇÂÖ∑‰ΩìÂÅöÊ≥ïÊòØÔºåÂ∞ÜÂèçÂêëËÆ°ÁÆóÁöÑ‰ºòÂÖàÁ∫ßË∞ÉÈ´òÔºå‰ΩøÂæóÁºñÂè∑ËæÉÂ∞èÁöÑ micro-batch ÁöÑÂèçÂêëÊ≠•È™§ÔºåËÉΩÂú®ÁºñÂè∑ËæÉÂ§ßÁöÑ micro-batch ÁöÑÂâçÂêëÊ≠•È™§‰πãÂâçÊâßË°å„ÄÇ‰ª•‰∏Ä‰∏™Â§öÈò∂ÊÆµÔºàstageÔºâÊµÅÊ∞¥Á∫ø‰∏∫‰æãÔºöÂ¶ÇÊûúÊàë‰ª¨ËÆ©ÊúÄÂêé‰∏Ä‰∏™ stage Âú®ÂÆåÊàêÂΩìÂâç micro-batch ÁöÑÂâçÂêëËÆ°ÁÆóÂêéÔºåÁ´ãÂàªÂêØÂä®ËØ• micro-batch ÁöÑÂèçÂêëËÆ°ÁÆóÔºåÈÇ£‰πàÂêéÁª≠ÁöÑÂêÑ‰∏™ stage Â∞±ËÉΩÊõ¥Êó©Âú∞Êî∂Âà∞ÂèçÂêëËÆ°ÁÆóÁöÑÊï∞ÊçÆÔºåËøõËÄåÂºÄÂßãÂÆÉ‰ª¨Ëá™Â∑±ÁöÑÂèçÂêëËÆ°ÁÆó„ÄÇÈÄöËøáËøôÁßç‚ÄúÂâçÂêëÂÅö‰∏ÄÊâπ„ÄÅÂèçÂêëÁ¥ßË∑ü‰∏ÄÊâπ‚ÄùÔºà1F1B one-forward-one-backwardÔºâÁöÑË∞ÉÂ∫¶Á≠ñÁï•Ôºå‰∏ç‰ªÖËÉΩÂ§üÂáèÂ∞ë activation Âú®ÊòæÂ≠ò‰∏≠ÁöÑÊªûÁïôÊó∂Èó¥ÔºåËøòËÉΩÂπ≥Ë°°ÂêÑ‰∏™ stage ÁöÑËÆ°ÁÆóË¥üËΩΩÔºåÊúÄÁªàÊúÄÂ§ßÂåñÊòæÂ≠òÂà©Áî®ÊïàÁéáÂπ∂Èôç‰ΩéÊï¥‰ΩìËÆ≠ÁªÉÊó∂ÁöÑÂÜÖÂ≠òÂ≥∞ÂÄºÈúÄÊ±Ç„ÄÇ

Âõ†Ê≠§Êàë‰ª¨ÂÆûÁé∞‰∫ÜÂ∞ÜÊøÄÊ¥ªÂÄºÊï∞Èáè‰∏äÈôê‰ªé micro-batch Êï∞Èáè **m** ÂèòÊàê pipeline stage Èò∂ÊÆµ **p**Ôºå‰ΩÜÂè™ÊòØÈôç‰Ωé‰∫ÜËÆæÂ§áÁöÑÂ≥∞ÂÄºÂÜÖÂ≠òÔºåÂπ∂Ê≤°ÊúâÈôç‰ΩéÊ∞îÊ≥°Â§ßÂ∞èÔºåÂõ†Ê≠§Á©∫Ê≥°Áéá‰∏éGpipe‰øùÊåÅ‰∏ÄËá¥Ôºå‰∏∫Ôºö
$$
\begin{equation}
bubble ration=\frac{t_{bubble}}{t_{ideal}}=\frac{p-1}{m}
\end{equation}
$$


![PipeDreamÂéüÁêÜ](images/10pipeline02.png)

## Virtual pipelineÂü∫Êú¨ÂéüÁêÜ

ÂêéÁª≠Megatron-LMÂú®1F1BÁöÑÂü∫Á°Ä‰∏äÂÅö‰∫ÜInterleaved 1F1BÁöÑ‰ºòÂåñÔºåÂáèÂ∞ë‰∫ÜÊµÅÊ∞¥Á∫øÊ∞îÊ≥°Ôºå‰πüÂ∞±ÊòØÊú¨ÁØá‰ªãÁªçÁöÑËôöÊãüÊµÅÊ∞¥Âπ∂Ë°åÔºàVirtual Pipeline ParallelismÔºåÁÆÄÁß∞VPPÔºâ„ÄÇ

VPPÁöÑÊ†∏ÂøÉÂú®‰∫éÔºåËÆ©‰∏Ä‰∏™Áâ©ÁêÜÂ±ÇÈù¢ÁöÑdeviceËôöÊãüÊàê‰∏∫v‰∏™devicesÔºådevice‰ªéËÆ°ÁÆó1‰∏™ÊàñËøûÁª≠layerÊÆµÂà∞ËÆ°ÁÆóv‰∏™‰∏çÁõ∏ÈÇªÁöÑlayerÔºåÂ¶ÇÂõæÊâÄÁ§∫ÔºöGPU1‰πãÂâçÂè™Ë¥üË¥£layer1Êàñlayer1+layer2Â±ÇÁöÑËÆ°ÁÆóÔºåÁªèËøáËôöÊãüÂåñÊµÅÊ∞¥Á∫øÂêéÔºåË¥üË¥£layer0Âíålayer5Â±ÇÁöÑËÆ°ÁÆóÔºå‰ΩøÂæólayer1Â±ÇËÆ°ÁÆóÂÆåÊàêÂêéÊó†ÈúÄÁ≠âÂæÖlayer2ÁöÑËÆ°ÁÆóÔºåÂèØ‰ª•Áõ¥Êé•ËøõÂÖ•GPU2ËøõË°åËÆ°ÁÆóÔºå‰ªéËÄåÂáèÂ∞ëÁ≠âÂæÖÁ©∫Ê≥°Êó∂Èó¥ÔºåÊ≠§Â§ÑvË¢´Áß∞‰∏∫ËôöÊãüÊµÅÊ∞¥Á∫øÈò∂ÊÆµÔºàvirtual pipeline stageÔºâ„ÄÇ
![ÂéüÁêÜ](images/10pipeline03.png)
ÂÅáËÆæÊ®°ÂûãÊÄªÂ±ÇÊï∞‰∏∫16ÔºåÂº†ÈáèÂπ∂Ë°åÂ§ßÂ∞ètp=1ÔºåÊµÅÊ∞¥Á∫øÂπ∂Ë°åÂ§ßÂ∞èpp=4ÔºåËôöÊãüÊµÅÊ∞¥Á∫øÂπ∂Ë°åÂ§ßÂ∞èv=2ÔºåÂàôÊ®°ÂûãÂ∞ÜË¢´ÂàíÂàÜ‰∏∫4 * 2 = 8‰∏™Èò∂ÊÆµÔºåÊØè‰∏™Èò∂ÊÆµÂåÖÂê´16 / 8 = 2‰∏™Â±Ç„ÄÇÂâçÂêëÁöÑÈ°∫Â∫è‰∏∫GPU 1 -> GPU 2 -> GPU 3 -> GPU 4 -> GPU 1 -> GPU 2 -> GPU 3 -> GPU 4„ÄÇ
Âú®ËÆæÂ§áÊï∞Èáè‰∏çÂèòÁöÑÊÉÖÂÜµ‰∏ãÔºåÂàÜÂá∫Êõ¥Â§öÁöÑÊµÅÊ∞¥Á∫øÈò∂ÊÆµÔºåËøôÊ†∑ÂèØ‰ª•ËÆ©ÊµÅÊ∞¥Á∫ø‰∏≠ÊØè‰∏™ stage Êõ¥Â∞èÔºåÂõ†ËÄå‰∏ã‰∏™ stage ÁöÑÁ≠âÂæÖÊó∂Èó¥Êõ¥Áü≠ÔºåÊ∞îÊ≥°Êõ¥Â∞è„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåmÈúÄË¶ÅÊòØpÁöÑÊï¥Êï∞ÂÄç„ÄÇ
![VirtualPPÂéüÁêÜ](images/10pipeline04.png)
ùëö‰∏∫micro-batchÔºåùëù‰∏∫pipeline stagesÔºåv‰∏∫ virtual pipeline stage,ÂÆåÊàêv‰∏™layerÊÆµ‰∏≠‰∏Ä‰∏™ÁöÑÂâçÂêë„ÄÅÂêéÂêëÊó∂Èó¥ÂàÜÂà´‰∏∫$t_f/v$Âíå$t_b/v$,ÊµÅÊ∞¥Á∫øÊ∞îÊ≥°ÁöÑËÄóÊó∂$t_{pd}^{int}$:
$$
\begin{equation}
t_{pd}^{int}=\frac{(p-1)*(t_f+t_b)}{v}
\end{equation}
$$
Âõ†Ê≠§ÂèØÂæóÂá∫VPPÁöÑÁ©∫Ê≥°ÁéáÔºö
$$
\begin{equation}
bubble ration=\frac{1}{v}*\frac{p-1}{m}
\end{equation}
$$
Á©∫Ê≥°ÁéáÈô§‰∫ÜË∑ü micro batch ÊàêÂèçÊØîÔºå‰∏é v ‰πüÊàêÂèçÊØî„ÄÇ

ÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåVPPÊòØ‰ª•Â¢ûÂä†ÈÄö‰ø°Èáè‰∏∫‰ª£‰ª∑ÔºåÊç¢ÂèñÊõ¥‰ΩéÁöÑÁ©∫Ê≥°ÊØîÁéáÔºåÁõ∏ÊØî‰∫é1FBÁé∞Âú®ÁöÑÊ∞îÊ≥°Âç†ÊØîÂ∞±ÂáèÂ∞ëÂà∞‰∫Ü1/v„ÄÇ‰ΩÜÊòØÊµÅÊ∞¥Á∫ø‰πãÈó¥ÁöÑÈÄö‰ø°Èáè‰πüÂ¢ûÂä†‰∫ÜvÂÄç„ÄÇÂØπ‰∫é‰∏Ä‰∏™ pipeline stageÔºåÈáåÈù¢ÂåÖÊã¨Â§ö‰∏™ Transformer layerÔºåÊâÄ‰ª•Áé∞Âú®Áõ∏ÂΩì‰∫éÊµÅÊ∞¥Á∫øÁöÑstageÂ¢ûÂä†‰∫ÜÔºåÈÄö‰ø°Èáè‰πü‰ºöÂ¢ûÂä†„ÄÇÁâπÂà´ÊòØÂΩìglobalÁöÑbatchË∂äÊù•Ë∂äÂ§ßÁöÑÊó∂ÂÄôÔºåËøô‰∏™ÈÄö‰ø°ÂºÄÈîÄÂ∞±‰ºöÊõ¥ÊòæËëó„ÄÇ

## Êñ∞ÂÖ¥PPÊäÄÊúØÔºàÊâ©ÂÖÖÔºâ

### PipeDream-2BW

PipeDream-2BW ÊòØ‰∏ÄÁßçÈù¢ÂêëË∂ÖÂ§ßËßÑÊ®°Ê∑±Â∫¶Ê®°ÂûãÁöÑÂºÇÊ≠•ÊµÅÊ∞¥Á∫øÂπ∂Ë°åÊñπÊ≥ïÔºöÂÆÉÂ∞ÜÊ®°ÂûãÂàáÂàÜ‰∏∫Â§ö‰∏™Èò∂ÊÆµÂπ∂Â§çÂà∂Â§öË∑ØÊµÅÊ∞¥Á∫øÔºåÂú® 1F1B Ë∞ÉÂ∫¶‰∏ãÈÄöËøá‚ÄúÂèåÁºìÂÜ≤‚ÄùÊùÉÈáçÊõ¥Êñ∞ÂíåÊ¢ØÂ∫¶ÂêàÂπ∂ÊäÄÊúØÔºåÂ§ßÂπÖÈôç‰ΩéÊòæÂ≠òÂç†Áî®‰∏éÈÄö‰ø°ÂºÄÈîÄÔºõÂÜÖÁΩÆÁöÑËá™Âä®Âåñ Planner Ê†πÊçÆËÆæÂ§áÂÜÖÂ≠òÂíå‰∫íËÅîÊãìÊâëÊêúÁ¥¢ÊúÄ‰ºòÈò∂ÊÆµÂàíÂàÜ‰∏éÂ§çÂà∂ÂÆΩÂ∫¶ÔºåÂπ∂ÂèØÈÄâÊøÄÊ¥ªÈáçËÆ°ÁÆóÔºõÂú®Â§öÂç°ÈõÜÁæ§‰∏äËÆ≠ÁªÉÂ§ßËßÑÊ®° Transformer Ê®°ÂûãÊó∂ÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÊµÅÊ∞¥Á∫øÂπ∂Ë°åÔºåÂêûÂêêÈáèÂèØÊèêÂçáÊï∞ÂÄçÔºåÂêåÊó∂‰øùÁïô‰∏éÊï∞ÊçÆÂπ∂Ë°å‰∏ÄËá¥ÁöÑÊùÉÈáçÊõ¥Êñ∞ËØ≠‰πâ„ÄÇ
![PipeDream-2BWÂéüÁêÜ](images/10pipeline05.png)

### ZB-V schedule

ZB-V schedule ÊòØ‰∏ÄÁßçÈù¢ÂêëÊµÅÊ∞¥Á∫øÂπ∂Ë°åÁöÑÂÜÖÂ≠òÈ´òÊïàÈõ∂Ê∞îÊ≥°Ë∞ÉÂ∫¶Á≠ñÁï•ÔºöÂÆÉÂ∞Üp‰∏™Èò∂ÊÆµÂàíÂàÜ‰∏∫2p‰∏™Ê®°ÂûãÂùóÔºåÂπ∂ÁªôÊØè‰∏™ worker ÂàÜÈÖç‰∏§‰∏™Ê®°ÂûãÂùóÔºåÊåâÁÖß‰ªéÈ¶ñÂà∞Â∞æÂÜçËøîÂõûÈ¶ñÁöÑVÂûãÈ°∫Â∫èËøõË°åÂàÜÈÖçÔºå‰ª•Á°Æ‰øùÊØè‰∏™ÂæÆÊâπÊ¨°ÁöÑÂâçÂêëÂíåÂØπÊùÉÈáçÁöÑÂêéÂêëÈÉΩÂú®Âêå‰∏Äworker‰∏äÊâßË°åÔºå‰ªéËÄåÂà©Áî®ÂêéÂêëÊùÉÈáçËÆ°ÁÆóÂ°´ÂÖÖÊµÅÊ∞¥Á∫øÁ©∫ÈöôÔºõÂú®‰∏é1F1BÁõ∏ÂêåÁöÑÊòæÂ≠òÁ∫¶Êùü‰∏ãÔºåÂèØÂú®Ê≠£Âêë„ÄÅÂêéÂêëËæìÂÖ•‰∏éÊùÉÈáçÂêéÂêëËÆ°ÁÆóÊó∂Èó¥Áõ∏Á≠âÊó∂ÂÆûÁé∞ËøëÈõ∂Ê∞îÊ≥°ÔºõÂêåÊó∂ÔºåËØ•Ë∞ÉÂ∫¶‰øùÊåÅÂêÑ worker Â≥∞ÂÄºÊøÄÊ¥ªÂÜÖÂ≠òÂùáË°°ÔºåÂÖºÈ°æÂêûÂêê‰∏éÊòæÂ≠òÊïàÁéá„ÄÇ
![ZB-V scheduleÂéüÁêÜ](images/10pipeline06.png)

### Hanayo wave-like pipeline

Hanayo ÊòØ‰∏ÄÁßçÊ≥¢Êµ™ÂºèÊµÅÊ∞¥Á∫øÂπ∂Ë°åÁ≠ñÁï•ÔºöÂÆÉÂ∞ÜÊ®°ÂûãÂàíÂàÜ‰∏∫S‰∏™Èò∂ÊÆµÂπ∂Â∞ÜÂ∞èÊâπÊ¨°ÂàÜÊàêW‰∏™Ê≥¢ÔºàwaveÔºâÔºå‰ª•Ê≥¢Êµ™ÂΩ¢ÁöÑÈ°∫Â∫èÂú®ÂêÑÈò∂ÊÆµ‰∫§ÈîôÊâßË°åÂâçÂêëÂíåÂêéÂêëËÆ°ÁÆóÔºåËÉΩÂ§üÂ∞ÜÊµÅÊ∞¥Á∫øÊ∞îÊ≥°ÊØî‰æãÈôç‰ΩéËá≥ÂéüÊù•ÁöÑ1/(2W) ‰∏îÊó†ÈúÄÂ§çÂà∂Ê®°ÂûãÔºå‰ªéËÄå‰øùÊåÅ‰∏é‰∏ªÊµÅÊñπÊ≥ï‰∏ÄËá¥ÁöÑÊùÉÈáçÂíåÊøÄÊ¥ªÂÜÖÂ≠òÂç†Áî®ÔºõÂêåÊó∂ÔºåÂÖ∂ËΩªÈáèÁ∫ßËøêË°åÊó∂ÂºïÊìéÂ∞ÜË∞ÉÂ∫¶ÈÄªËæë‰∏éÊâßË°åÂíåÈÄö‰ø°‰ºòÂåñËß£ËÄ¶ÔºåÊîØÊåÅÂú®Â§öÂç°ÈõÜÁæ§‰∏äÁÅµÊ¥ªÈÉ®ÁΩ≤ÔºõÂú®ÂØπGPTÂíåBERTÁ±ªÊ®°Âûã„ÄÅÊúÄÂ§ö32ÂùóGPUÁöÑÊµãËØï‰∏≠ÔºåHanayoÁõ∏ËæÉÊúÄÂÖàËøõÊñπÊ°àÂÆûÁé∞‰∫ÜÊúÄÈ´ò30.4%ÁöÑÂêûÂêêÈáèÊèêÂçá
![Hanayo wave-likeÂéüÁêÜ](images/10pipeline07.png)

## ÂàÜÂ∏ÉÂºèÊ°ÜÊû∂ÈáåÁöÑPPÂÆûÁé∞

- Ê®°ÂûãËøêË°åÂÖ•Âè£‰∏éPPÈÖçÁΩÆÔºö
pretrain_gpt.py mainÂáΩÊï∞Ë∞ÉÁî®pretrain->get_model,get_modelÂáΩÊï∞Âà§Êñ≠pipelineÁöÑÂàíÂàÜÁ≠ñÁï•
```
Megatron-LM/pretrain_gpt.py

if __name__ == "__main__":

    # Temporary for transition to core datasets
    train_valid_test_datasets_provider.is_distributed = True

    # Optionally enable inprocess restart on pretrain
    pretrain, store = inprocess_restart.maybe_wrap_for_inprocess_restart(pretrain)

    pretrain(
        train_valid_test_datasets_provider,
        model_provider,
        ModelType.encoder_or_decoder,
        forward_step,
        args_defaults={'tokenizer_type': 'GPT2BPETokenizer'},
        extra_args_provider=add_modelopt_args if has_nvidia_modelopt else None,
        store=store,
    )
```

pretrainÂáΩÊï∞ÂÜÖÈÉ®Ë∞ÉÁî®setup_model_and_optimizerÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞ÂÜÖÈÉ®Ë∞ÉÁî®get_model
```
Megatron-LM/megatron/training/training.py/def pretrain

# Model, optimizer, and learning rate.
timers('model-and-optimizer-setup', log_level=0).start(barrier=True)
app_metrics['app_build_optimizer_start_time'] = one_logger_utils.get_timestamp_in_ms()
model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
    model_provider, model_type, checkpointing_context=checkpointing_context
)

Megatron-LM/megatron/training/training.py/def setup_model_and_optimizer

def setup_model_and_optimizer(
    model_provider_func,
    model_type,
    no_wd_decay_cond=None,
    scale_lr_cond=None,
    lr_mult=1.0,
    checkpointing_context=None,
):
    """Setup model and optimizer."""
    args = get_args()
    timers = get_timers()
    one_logger = get_one_logger()

    model = get_model(model_provider_func, model_type)
    unwrapped_model = unwrap_model(model)
```

get_modelÈÄöËøáget_argsÂáΩÊï∞ÊãøÂà∞ÂêØÂä®ËÑöÊú¨ËÆæÁΩÆÁöÑË∂ÖÂèÇÔºåÂèÇÊï∞ËÆæÁΩÆÂ¶ÇÂõæÊâÄÁ§∫Ôºö
![argsË∂ÖÂèÇËÆæÁΩÆ](images/10pipeline08.png)
```
Megatron-LM/megatron/training/training.py/def get_model

def get_model(model_provider_func, model_type=ModelType.encoder_or_decoder, wrap_with_ddp=True):
    """Build the model."""
    args = get_args()
    args.model_type = model_type

    # Build model.
```

Ê≠§Â§ÑÂàÜ‰∏∫‰∏§ÁßçÊÉÖÂÜµËÆ®ËÆ∫Ôºå‰ª•‰∏ãÊòØÂêØÁî®ËôöÊãüÁÆ°ÈÅì(VPP)ÁöÑÊ®°ÂûãÊûÑÂª∫ÔºåÂà§Êñ≠Êù°‰ª∂Â¶ÇÁ¨¨‰∏Ä‰∏™ifÊâÄÁ§∫„ÄÇÂà§ÂÆöÈÄªËæëÊ†áËÆ∞‰∫ÜÔºöÂè™ÊúâÁ¨¨‰∏Ä‰∏™rankÂÅöËæìÂÖ•ÔºåÊúÄÂêé‰∏Ä‰∏™rankÂÅöËæìÂá∫ÔºåÂà©Áî®model_provider_funcÂáΩÊï∞ËÆ°ÁÆóÂΩìÂâçRankËØ•‚ÄúÂàá‚ÄùÂì™‰∏ÄÊÆµ Transformer Â±ÇÂπ∂ÂÆû‰æãÂåñÔºåÊúÄÁªàÊääÊâÄÊúâRankÊåâÈ°∫Â∫èÊîæÂÖ•modelÂàóË°®Ôºå‰æõÂêéÈù¢ÁöÑÊµÅÊ∞¥Á∫øË∞ÉÂ∫¶Âô®Âæ™ÁéØË∞ÉÁî®„ÄÇ
```
Megatron-LM/megatron/training/training.py/def get_model
 
  if (
            mpu.get_pipeline_model_parallel_world_size() > 1
            and args.virtual_pipeline_model_parallel_size is not None
        ):
            if model_type == ModelType.encoder_and_decoder:
                assert (
                    args.encoder_pipeline_model_parallel_size == 0
                ), "Interleaved schedule not supported for model with encoder on separate PP rank"
            model = []
            for i in range(args.virtual_pipeline_model_parallel_size):
                # Set pre_process and post_process only after virtual rank is set.
                pre_process = mpu.is_pipeline_first_stage(ignore_virtual=False, vp_stage=i)
                post_process = mpu.is_pipeline_last_stage(ignore_virtual=False, vp_stage=i)
                this_model = model_provider_func(
                    pre_process=pre_process, post_process=post_process, vp_stage=i)
                this_model.model_type = model_type
                this_model.vp_stage = i
                model.append(this_model)
```

Âê¶ÂàôÂêØÁî®PipeDreamÊµÅÊ∞¥Á∫øÂπ∂Ë°åÔºåÊ†πÊçÆÊ®°ÂûãÁ±ªÂûãÂíåÂπ∂Ë°åÂ∫¶ÔºåÂ∞ÜÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®Ê®°ÂùóÂêàÁêÜÂú∞ÊãÜÂàÜÂà∞‰∏çÂêå GPUÔºå‰øùËØÅÂâçÂêë/ÂèçÂêë‰º†ÈÄíÁöÑÊ≠£Á°ÆÊÄß‰∏éÈ´òÊïàÊÄß„ÄÇ
```
Megatron-LM/megatron/training/training.py/def get_model

else:
            pre_process = mpu.is_pipeline_first_stage()
            post_process = mpu.is_pipeline_last_stage()
            add_encoder = True
            add_decoder = True
            if model_type == ModelType.encoder_and_decoder:
                if mpu.get_pipeline_model_parallel_world_size() > 1:
                    rank = mpu.get_pipeline_model_parallel_rank()
                    first_decoder_rank = args.encoder_pipeline_model_parallel_size
                    world_size = mpu.get_pipeline_model_parallel_world_size()
                    pre_process = rank == 0 or rank == first_decoder_rank
                    post_process = (rank == (first_decoder_rank - 1)) or (rank == (world_size - 1))
                    add_encoder = mpu.is_inside_encoder(rank)
                    add_decoder = mpu.is_inside_decoder(rank)
                model = model_provider_func(
                    pre_process=pre_process,
                    post_process=post_process,
                    add_encoder=add_encoder,
                    add_decoder=add_decoder,
                )
            else:
                model = model_provider_func(pre_process=pre_process, post_process=post_process)
            model.model_type = model_type
        return model
```

- PPÊ®°ÂûãÂÆû‰æãÂåñÔºöÔºàÊ≤°ÊâæÂÖ®Ôºâ

ÈÄöËøá‰∏äËø∞get_modelÂáΩÊï∞ÈáåÁöÑmodel_provider_funcÂáΩÊï∞ÊûÑÂª∫Ê®°ÂûãÂÆû‰æãÔºåmodel_provider_funcÂπ∂‰∏çÊòØMegatron-CoreÂ∫ìÈáå‰∏Ä‰∏™ÂçïÁã¨ÁöÑÂÖ®Â±ÄÂáΩÊï∞ÔºåËÄåÊòØÁî±ÂêÑ‰∏™È¢ÑËÆ≠ÁªÉËÑöÊú¨(Â¶Ç pretrain_gpt.py)ÂÆö‰πâÂπ∂‰º†ÂÖ•Ê†∏ÂøÉËÆ≠ÁªÉÊµÅÁ®ãÁöÑÂõûË∞É„ÄÇ
```
Megatron-LM/pretrain_gpt.py

def model_provider(
    pre_process=True, post_process=True, vp_stage: Optional[int] = None
) -> Union[GPTModel, megatron.legacy.model.GPTModel]:
```

ÊûÑÂª∫GPTModelÂÆû‰æãÔºå
```
Megatron-LM/megatron/core/models/gpt/gpt_model.py

class GPTModel(LanguageModule):
    def __init__(...):

        # Transformer.
        self.decoder = TransformerBlock(
            config=self.config,
            spec=transformer_layer_spec,
            pre_process=self.pre_process,
            post_process=self.post_process,
            vp_stage=vp_stage,
        )
```

- PPËé∑ÂèñÈúÄË¶ÅÊâßË°åÁöÑÂ±ÇÊï∞ÔºöÔºàÊ≤°ÁúãÊáÇÔºâ

TransformerBlockÊ≥®ÂÜåÈÄöËøáget_num_layers_to_buildËÆ°ÁÆóÂΩìÂâçStageÂåÖÂê´Âá†‰∏™Transformer Layer
```
Megatron-LM/megatron/core/transformer/transformer_block.py

def get_num_layers_to_build(config: TransformerConfig, vp_stage: Optional[int] = None) -> int:
    return num_layers_to_build

class TransformerBlockSubmodules:

    def _get_block_submodules(...):

    if isinstance(spec, TransformerBlockSubmodules):
            return spec

        # ModuleSpec here is generally assumed to be for a transformer layer that
        # is implemented in `transformer_layer.py` or if it subclasses
        # `BaseTransformerLayer` from the `transformer_layer.py` file.
        elif isinstance(spec, ModuleSpec):
            if issubclass(spec.module, TransformerBlock):
                return spec.submodules
            elif issubclass(spec.module, BaseTransformerLayer):
                num_layers = get_num_layers_to_build(config, vp_stage)
                return TransformerBlockSubmodules(
                    layer_specs=[spec] * num_layers, layer_norm=LayerNormImpl
                )
            else:
                raise Exception(f"specialize for {spec.module.__name__}.")
        else:
            raise Exception(f"specialize for {type(spec).__name__}.")
```

Âú® GPT Ê®°ÂûãËøêË°åÁ§∫‰æã‰∏≠ÊØè‰∏™ Stage build_layer ÁöÑ‰∏™Êï∞‰∏∫ number_lyaer = L / PP_num
```
Megatron-LM/megatron/core/transformer/transformer_block.py

class TransformerBlock(MegatronModule):
    """Transformer class."""

    def __init__Ôºà
        self.num_layers_per_pipeline_rank = len(self.layers)

    def _build_layers(self):
        # Transformer layers.
        # @jcasper can we improve how we deal with layer_number?
        # currently it's only used in CoreAttention?
        # if self.apply_query_key_layer_scaling:
        #     coeff = self.layer_number
        #     self.norm_factor *= coeff
        def build_layer(layer_spec, layer_number):
            global_layer_number = layer_number + get_transformer_layer_offset(
                self.config, self.vp_stage
            )  # 1-based index
            if self.config.heterogeneous_block_specs:
                layer_config = self.config.get_config_for_layer(global_layer_number)
            else:
                layer_config = self.config
```

- ÊâßË°åPPËÆ≠ÁªÉÔºö

GPTËÆ≠ÁªÉË∞ÉÁî® pretrain -> train -> train_stepÔºåÊâßË°å‰∏Ä‰∏™ iteration, train_stepÂáΩÊï∞ÈÄöËøáget_forward_backward_fun()ÂáΩÊï∞ËøõÂÖ•schedulers.pyÊ®°ÂùóÔºåÂπ∂Ê†πÊçÆÂΩìÂâçÁöÑ PP Ê®°ÂºèËøîÂõûforward_backward_pipelining_with_interleavingÊâßË°åÂâçÂêëÂíåÂèçÂêëËÆ°ÁÆó
```
Megatron-LM/megatron/training/training.py

def train_step(forward_step_func, data_iterator, model, optimizer, opt_param_scheduler, config):
    """Single training step."""
            ...
    # Forward pass.
        forward_backward_func = get_forward_backward_func()
        losses_reduced = forward_backward_func(
            forward_step_func=forward_step_func,
            data_iterator=data_iterator,
            model=model,
            num_microbatches=get_num_microbatches(),
            seq_length=args.seq_length,
            micro_batch_size=args.micro_batch_size,
            decoder_seq_length=args.decoder_seq_length,
            forward_only=False,
            adjust_tensor_shapes_fn=adjust_tensor_shapes_fn,
        )


Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def get_forward_backward_func():
    pipeline_model_parallel_size = parallel_state.get_pipeline_model_parallel_world_size()
    if pipeline_model_parallel_size > 1:
        if parallel_state.get_virtual_pipeline_model_parallel_world_size() is not None:
            forward_backward_func = forward_backward_pipelining_with_interleaving
        else:
            forward_backward_func = forward_backward_pipelining_without_interleaving
    else:
        forward_backward_func = forward_backward_no_pipelining
    return forward_backward_func
```

- NPU0ÊâßË°åstage0Ôºà‰∏çÊ∏ÖÊô∞Ôºâ

ÊâßË°å Forward ËÆ°ÁÆóÔºåÈÄâÊã© forward_backward_pipelining_without_interleavingÊ®°Âºè
(‰ª•Pipeline 1F1B‰∏∫‰æãÔºåÂç≥PipeDream) ÂÖàÂÖ≥Èó≠Ê¢ØÂ∫¶Êõ¥Êñ∞ÔºåÁ≠âÊâÄÊúâÁöÑmicrobatchÊâßË°åÂÆåÊØïÊâçÊõ¥Êñ∞Ê¢ØÂ∫¶„ÄÇËøáÁ®ãÂ¶ÇÂõæÊâÄÁ§∫Ôºö
![argsË∂ÖÂèÇËÆæÁΩÆ](images/10pipeline10.png)

ÈÉ®ÂàÜ‰ª£Á†ÅÂ±ïÁ§∫Ôºö
ÂÖ∂‰∏≠Ôºönum_microbatchesÔºöÊÄªÁöÑ micro batch ‰∏™Êï∞„ÄÇnum_warmup_microbatchesÔºöÂΩìÂâçrank warmupÈò∂ÊÆµÈúÄË¶ÅËÆ°ÁÆóÔºåÁõ¥Âà∞1F1B ÁöÑmicrobatchÁöÑ‰∏™Êï∞„ÄÇ
num_microbatches_remainingÔºöÂΩìÂâçrankËøòÂâ©‰∏ãÂ§öÂ∞ë‰∏™microbatchÊâßË°åÊâçÂà∞1F1BÈò∂ÊÆµÔºåÂç≥num_microbatches - num_warmup_microbatches„ÄÇ
```
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def forward_backward_pipelining_without_interleaving(
    ...
    micro_batch_size: int,
    ...
):
    ...
    disable_grad_sync()

    # Compute number of warmup microbatches.
    num_warmup_microbatches = (
        parallel_state.get_pipeline_model_parallel_world_size()
        - parallel_state.get_pipeline_model_parallel_rank()
        - 1
    )
    num_warmup_microbatches = min(num_warmup_microbatches, num_microbatches)
    num_microbatches_remaining = num_microbatches - num_warmup_microbatches
```

- NPU0ÂÆåÊàêÂâçÂêëËÆ°ÁÆóÔºåÂ¶ÇÂõæÊâÄÁ§∫Ôºö
NPU0Âú®stage0Èò∂ÊÆµÊ≤°ÊúâÂÖ∂ÂÆÉÁöÑStageÊøÄÊ¥ªËæìÂÖ•ÔºåÂõ†Ê≠§ÂøΩÁï•recv_forward()ÂáΩÊï∞Ôºåforward_stepË∞ÉÁî® forward_step_func ÁúüÊ≠£Ë∞ÉÁî®Ê®°ÂûãÊâßË°åÔºö
![NPU0ÂÆåÊàêFI](images/10pipeline12.png)

```
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

 # Run warmup forward passes.
    for i in range(num_warmup_microbatches):
        # Decide to checkpoint all layers' activations of the current micro-batch
        if max_outstanding_backprops is not None:
            checkpoint_activations_microbatch = (
                i % max_outstanding_backprops
                >= config.num_microbatches_with_partial_activation_checkpoints
            )
        else:
            checkpoint_activations_microbatch = None

        input_tensor = recv_forward(
            recv_tensor_shapes, config, parallel_state.is_pipeline_first_stage()
        )
        output_tensor, num_tokens = forward_step(
            forward_step_func,
            data_iterator,
            model,
            num_microbatches,
            input_tensor,
            forward_data_store,
            config,
            collect_non_loss_data,
            checkpoint_activations_microbatch,
            check_first_val_step(first_val_step, forward_only, i == 0),
            current_microbatch=i,
            encoder_decoder_xattn=encoder_decoder_xattn,
        )

        def forward_step(...)
            ...
            if config.enable_autocast:
                context_manager = torch.autocast("cuda", dtype=config.autocast_dtype)
            else:
                context_manager = contextlib.nullcontext()
            with context_manager:
                if checkpoint_activations_microbatch is None:
                    output_tensor, loss_func = forward_step_func(data_iterator, model)
                else:
                    output_tensor, loss_func = forward_step_func(
                        data_iterator, model, checkpoint_activations_microbatch
                    )
```
- NPU0ÂâçÂêë‰º†ÈÄíÊøÄÊ¥ªÔºåÂ¶ÇÂõæÊâÄÁ§∫Ôºö
![NPU0‰º†ÈÄíÊøÄÊ¥ª](images/10pipeline13.png)
NPU0‰∏äËæìÂá∫Stage0 output_tensorÂêésend_forwardÂèëÈÄÅÁªô‰∏ã‰∏Ä‰∏™StageÔºåÈÄöËøáP2P_communication.send_forwardÂèëÈÄÅoutput_tensorÔºåÈÄöËøátorch.distributed.P2POpÂºÇÊ≠•send output_tensorÔºåÊúÄÂêéË∞ÉÁî® torch.cuda.synchronize() ÊâßË°åÂêåÊ≠•
```
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

        send_forward(
            output_tensor, send_tensor_shapes, config, parallel_state.is_pipeline_last_stage()
        )

        def send_forward(output_tensors, tensor_shapes, config, is_last_stage):
    """Wrapper for p2p_communication.send_forward used with non-interleaving schedule."""
    if not isinstance(output_tensors, list):
        output_tensors = [output_tensors]
    for output_tensor, tensor_shape in zip(output_tensors, tensor_shapes):
        if tensor_shape is None:
            continue
        p2p_communication.send_forward(output_tensor, config, is_last_stage)

Megatron-LM/megatron/core/pipeline_parallel/p2p_communication.py

      if wait_on_reqs and len(reqs) > 0:
        for req in reqs if isinstance(reqs, list) else reqs.values():
            req.wait()
        reqs = None

    if (
        (config.batch_p2p_comm and config.batch_p2p_sync)
        # The lists below have a size > 1 only when ETP ‚â† DTP,
        # meaning this synchronization is required when ETP ‚â† DTP.
        or len(tensor_recv_prev_list) > 1
        or len(tensor_recv_next_list) > 1
    ):
        # To protect against race condition when using batch_isend_irecv().
        # User should assert that we have a modern enough PyTorch to not need this
        torch.cuda.synchronize()    
```

- NPU0ÁªßÁª≠ËÆ°ÁÆóÔºö
NPU0ÁªßÁª≠ÊâßË°åforward_step,Stage0ÂâçÂêëËÆ°ÁÆóÂæóÂà∞Á¨¨‰∫å‰∏™output_tensor,Âà©Áî®sedn_forward_recv_backwardÂáΩÊï∞ÂèëÈÄÅoutput_tensorÁ≠âÂæÖbackwardÔºåËøõÂÖ•1F1BÁä∂ÊÄÅÔºåÈÄöËøásend_backward_recv_backwardÂ∫ïÂ±ÇËØï‰∏ãÈÄöËøáP2PPpÂºÇÊ≠•Ôºåsend output_tesnorÔºå‰∏îÂºÇÊ≠•recv tensor_recv_nextÔºåÊúÄÂêéË∞ÉÁî®synchronize()Á≠âÂæÖrecv backwardÔºåNPU0ËøõÂÖ•Á≠âÂæÖÁä∂ÊÄÅ„ÄÇ
![NPU0ËÆ°ÁÆóF2](images/10pipeline17.png)

```
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def forward_backward_pipelining_without_interleaving(...):
 def enable_grad_sync():
    # Run warmup forward passes.
    for i in range(num_warmup_microbatches):
        # Decide to checkpoint all layers' activations of the current micro-batch
        if max_outstanding_backprops is not None:
            checkpoint_activations_microbatch = (
                i % max_outstanding_backprops
                >= config.num_microbatches_with_partial_activation_checkpoints
            )
        else:
            checkpoint_activations_microbatch = None

        input_tensor = recv_forward(
            recv_tensor_shapes, config, parallel_state.is_pipeline_first_stage()
        )
        output_tensor, num_tokens = forward_step(
            forward_step_func,
            data_iterator,
            model,
            num_microbatches,
            input_tensor,
            forward_data_store,
            config,
            collect_non_loss_data,
            checkpoint_activations_microbatch,
            check_first_val_step(first_val_step, forward_only, i == 0),
            current_microbatch=i,
            encoder_decoder_xattn=encoder_decoder_xattn,
        )
```

- NPU1ËøõË°åÂâçÂêëËÆ°ÁÆóÔºö
ÂÖ∂ËøáÁ®ãÂêåGPU0‰∏ÄËá¥ÔºåÂ¶ÇÂõæÊâÄÁ§∫Ôºö
num_warmup_microbatches=0ÔºåËøõÂÖ•1F1BÁä∂ÊÄÅÔºånum_microbatches_remaining=3Ôºårecv_forward Ë∞ÉÁî® P2POp ÂºÇÊ≠•recvÔºåNPU1 ÊúÄÂêéË∞ÉÁî®synchronize() ÊâßË°åÂêåÊ≠•Á≠âÂæÖ NPU0 Stage0 ËæìÂá∫Ôºå‰ªéËÄå‰øùËØÅNPU0 to NPU1 ÁöÑÊâßË°åÈ°∫Â∫è„ÄÇ
![NPU1ËÆ°ÁÆó](images/10pipeline14.png)
NPU1 recv_forwardÁ≠âÂæÖNPU0 Stage0ÂèëÈÄÅintput_tensorÂêéNPU1 forward_stepËÆæÁΩÆiNPUt_tensorÔºåÂÆûÁé∞NPU0&NPU1‰∫§Êç¢ËæìÂÖ•ËæìÂá∫NPU1ËøõÂÖ•1F1BÂæ™ÁéØÔºåforward_step_funcË∞ÉÁî®GPTModelÊâßË°åÂâçÂêëËÆ°ÁÆó„ÄÇNPU1 ‰∏äTransformerBlock ÊâßË°åÁ¨¨‰∏Ä‰∏™ StageÔºåPre_process=FalseÔºåÂç≥‰∏ç‰ºöÊääiNPUt_embeddings‰Ωú‰∏∫ransformerÁöÑËæìÂÖ•Ôºå‰ΩøÁî®NPU0 Stage0ËæìÂÖ•ÁöÑiNPUt_tensor‰Ωú‰∏∫ËæìÂÖ•ÊâßË°åÂæóÂà∞output tensor„ÄÇ
![NPU1ËÆ°ÁÆó](images/10pipeline15.png)
```
Megatron-LM/megatron/core/transformer/transformer_block.py

class TransformerBlock(MegatronModule):
    """Transformer class."""

    def __init__(
        self,
        config: TransformerConfig,
        spec: Union[TransformerBlockSubmodules, ModuleSpec],
        post_layer_norm: bool = True,
        pre_process: bool = False,
        post_process: bool = True,
        model_comm_pgs: ModelCommProcessGroups = None,
        vp_stage: Optional[int] = None,
    ):
        super().__init__(config=config)

        self.submodules = _get_block_submodules(config, spec, vp_stage)
        self.post_layer_norm = post_layer_norm
        self.pre_process = pre_process
        self.post_process = post_process
        self.vp_stage = vp_stage

    def forward(...):
        if not self.pre_process:
            # See set_input_tensor()
            hidden_states = self.input_tensor
```
Á§∫‰æã‰∏≠NPU1 Stage1ÊòØÊúÄÂêé‰∏ÄÂ±ÇStaegeÔºåÂõ†Ê≠§post_process=True,ÊâßË°å is_pipeline_last_stageËÆ°ÁÆóGPTÊ®°ÂûãÁöÑoutput_tensorÂíåloss„ÄÇ

![NPU1ËÆ°ÁÆó](images/10pipeline16.png)

```
Megatron-LM/megatron/core/transformer/transformer_block.py

class TransformerBlock(MegatronModule):
    """Transformer class."""

    def __init__(
        self,
        config: TransformerConfig,
        spec: Union[TransformerBlockSubmodules, ModuleSpec],
        post_layer_norm: bool = True,
        pre_process: bool = True,
        post_process: bool = True,
        model_comm_pgs: ModelCommProcessGroups = None,
        vp_stage: Optional[int] = None,
    ):

Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def forward_step(...)
    ...
   if parallel_state.is_pipeline_last_stage(ignore_virtual=False, vp_stage=vp_stage):
        if not collect_non_loss_data:
            outputs = loss_func(output_tensor)
            if len(outputs) == 3:
                output_tensor, num_tokens, loss_reduced = outputs
                if not config.calculate_per_token_loss:
                    output_tensor /= num_tokens
                    output_tensor /= num_microbatches
            else:
                # preserve legacy loss averaging behavior (ie, over the number of microbatches)
                assert len(outputs) == 2
                output_tensor, loss_reduced = outputs
                output_tensor *= parallel_state.get_context_parallel_world_size()
                output_tensor /= num_microbatches
            forward_data_store.append(loss_reduced)
        else:
            data = loss_func(output_tensor, non_loss_data=True)
            forward_data_store.append(data)
```

- NPU1ÂèçÂêëÊâßË°åStage1Ôºö
ÊâßË°åÂÆåforward_stepÂêéÊâßË°åbackward_stepÂæóÂà∞iNPUt_tensor_gradÔºåÂπ∂
ËøõÂÖ•1F1BÁä∂ÊÄÅÔºåÊâßË°åsend_backward_recc_forward->_communication->ÂºÇÊ≠•ÂèëÈÄÅiNPUt_tensor_gradÁªôNPU0Âπ∂Á≠âÂæÖNPU0ÂèëÈÄÅ‰∏ã‰∏Ä‰∏™MB forwardÁªìÊûú„ÄÇ

![NPU1ÂèçÂêëËÆ°ÁÆó](images/10pipeline18.png)

```
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def forward_backward_pipelining_without_interleaving(...):
    # Enable grad sync for the last microbatch in the batch if the full
    # backward pass completes in the 1F1B stage.
    if num_warmup_microbatches == 0 and last_iteration:
        if config.grad_sync_func is None or rank == 0:
            enable_grad_sync()

    input_tensor_grad = backward_step(
        input_tensor, output_tensor, output_tensor_grad, model_type, config
    )

    if last_iteration:
        input_tensor = None
        send_backward(
            input_tensor_grad,
            recv_tensor_shapes,
            config,
            parallel_state.is_pipeline_first_stage(),
        )
    else:
        input_tensor = send_backward_recv_forward(
            input_tensor_grad,
            recv_tensor_shapes,
            config,
            parallel_state.is_pipeline_first_stage(),
        ) 

def send_backward_recv_forward(input_tensor_grads, tensor_shapes, config, is_first_stage):
    """Wrapper for p2p_communication.send_backward_recv_forward used
    with non-interleaving schedule."""
    if not isinstance(input_tensor_grads, list):
        input_tensor_grads = [input_tensor_grads]
    input_tensors = []
    for input_tensor_grad, tensor_shape in zip(input_tensor_grads, tensor_shapes):
        if tensor_shape is None:
            input_tensors.append(None)
            continue
        input_tensor = p2p_communication.send_backward_recv_forward(
            input_tensor_grad, tensor_shape, config, is_first_stage
        )
        input_tensors.append(input_tensor)
    return input_tensors
```

- NPU0ÂèçÂêëÊâßË°åStage0Ôºö
NPU0 Srage0Á≠âÂæÖsend_backward_recv_forwardË¢´Âî§ÈÜíÂêéËé∑ÂæóNPU1 Staege1ÂèëÈÄÅÁöÑoutput_tensor_gradÔºåNPU0 Stage0ÊâßË°åbackward_stepËæìÂá∫intput_tensor_gradÔºåNPU0ËÆ°ÂÖ•1F1BÁä∂ÊÄÅÔºåNPU0 num_warmup_mbs=1, num_mbs_remaining=2ÔºåËøõÂÖ•1F1BÂæ™ÁéØÔºåÊâßË°åforward_stepÊâßË°åStarge1ÂâçÂêëËÆ°ÁÆóÂæóÂà∞output_tensor(Forward 3)ÔºåÊâßË°åsend_forward_recv_backwardÂèëÈÄÅoutput_tensorÁ≠âÂæÖbackwardÔºåÂºÇÊ≠•recv tensor_recv_nextÔºåË∞ÉÁî®synnchronize()ÂêåÊ≠•Á≠âÂæÖbackwardÔºåNPU0 ËøõÂÖ•Á≠âÂæÖÁä∂ÊÄÅ„ÄÇ

![NPU0ÂèçÂêë‰º†Ëæì](images/10pipeline19.png)

```
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

 # Run 1F1B in steady state.
    for i in range(num_microbatches_remaining):
        last_iteration = i == (num_microbatches_remaining - 1)

        # Decide to checkpoint all layers' activations of the current micro-batch
        if max_outstanding_backprops is not None:
            checkpoint_activations_microbatch = (
                (i + num_warmup_microbatches) % max_outstanding_backprops
            ) >= config.num_microbatches_with_partial_activation_checkpoints
        else:
            checkpoint_activations_microbatch = None

        output_tensor, num_tokens = forward_step(...)
        total_num_tokens += num_tokens

        if forward_only:
            send_forward(
                output_tensor, send_tensor_shapes, config, parallel_state.is_pipeline_last_stage()
            )

            if not last_iteration:
                input_tensor = recv_forward(
                    recv_tensor_shapes, config, parallel_state.is_pipeline_first_stage()
                )

        else:
            output_tensor_grad = send_forward_recv_backward(
                output_tensor, send_tensor_shapes, config, parallel_state.is_pipeline_last_stage()
            )


Megatron-LM/megatron/core/pipeline_parallel/p2p_communication.py

  if recv_prev:
        if config.pipeline_dtype is None:
            raise RuntimeError("pipeline_dtype must be provided if recv_prev is True")
        if tensor_shape is None:
            raise RuntimeError(
                "tensor_shape must be specified if recv_prev is True. "
                "Common tensor_shape is (seq_length, micro_batch_size, hidden_size)"
            )
        tensor_recv_prev_func = create_tensor_recv_prev

    if recv_next:
        if config.pipeline_dtype is None:
            raise RuntimeError("dtype must be provided if recv_next is True")
        if tensor_shape is None:
            raise RuntimeError(
                "tensor_shape must be specified if recv_next is True. "
                "Common tensor_shape is (seq_length, micro_batch_size, hidden_size)"
            )
        tensor_recv_next_func = create_tensor_recv_next
```

- NPU1ÂèçÂêëÊâßË°åStage1Ôºö
ÂêåÁêÜÔºåNPU1 Stage1‰∏äÊâßË°åsend_backward_recv_forwardÂêåÊ≠•Á≠âÂæÖÊî∂Âà∞NPU0
Stge0ÂèëÈÄÅiNPUt_tensorÔºàForward 2Ôºâ,NPU1 Stage1Â∞ÜiNPUt_tensorÔºàForward 2Ôºâ‰Ωú‰∏∫TransformerBlockÊâßË°åforward_step,ÂæóÂà∞ËæìÂá∫output_tensor„ÄÇ
![NPU1ÂèçÂêë‰º†Ëæì](images/10pipeline19.png)

- NPU0ÊâßË°åStage0
NPU0Á≠âÂæÖsend_forward_recv_backwardÊâßË°åNPU1ËæìÂá∫output_grad(B2)ÔºåÊâßË°åbackward_stepËæìÂá∫iNPUt_tensor_gradÔºàB2ÔºâÔºåNPU0 num_warmup_mbs=1, num_mbs_remaing=2, i=2ÔºåÈÄÄÂá∫ 1F1BÔºåËøõÂÖ•cooldown backwrd pass enable_grad_syncÊâìÂºÄÊ®°ÂûãÊ¢ØÂ∫¶Êõ¥Êñ∞Ôºårecv_backwardÁ≠âÂæÖNPU1ÂèëÈÄÅÊúÄÂêé‰∏Ä‰∏™ mbs ÁöÑbackwardÔºàB3ÔºâÔºåNPU0 ÂáÜÂ§áÊõ¥Êñ∞Ê®°ÂûãÁöÑÊ¢ØÂ∫¶ÂíåÂèÇÊï∞„ÄÇ
![NPU1ÂèçÂêë‰º†Ëæì](images/10pipeline20.png)

- NPU1ÊâßË°åStage1
NPU1 Stage1ÊâßË°åsend_backward_recv_forwardÂêåÊ≠•Á≠âÂæÖiNPUt(F3),NPU1 num_warmup_mbs=0Ôºånum_mbs_remaining=3ÔºåËøõÂÖ•1F1BÂæ™ÁéØ,Â∞ÜNPU0 Stage0ÂèëÈÄÅ iNPUt(F3)‰Ωú‰∏∫TransformerBlockÁöÑiNPUtËÆ°ÁÆóÂâçÂêë,forward_step()ËæìÂá∫output (F3)ÊâßË°åbackward_step()ÂæóÂà∞iNPUt_tensor_grad(B3),send_backward()ÂºÇÊ≠•ÂèëÈÄÅiNPUt_tesnor_grad(B3)ÁªôNPU0„ÄÇ
![NPU1ÂèçÂêë‰º†Ëæì](images/10pipeline21.png)

- NPU0ÊâßË°åStage0ÂêéÔºåÊâßË°åÂÆåÂÆåÊï¥ÁöÑiteration
NPU0Á≠âÂæÖcooldown backwardÁöÑrecv_backward()Ëé∑ÂæóNPU1ËæìÂá∫(B3)ÔºåÊâßË°å backward_step()ËæìÂá∫iNPUt_tensor_grad(B3)Ôºåforward_backward_func()ËøîÂõûLOSSÔºåenable_grad_sync()Á¥ØÂä†Êõ¥Êñ∞Ê®°ÂûãÊ¢ØÂ∫¶Ôºåfinalize_model_grads_func()Êõ¥Êñ∞Ê®°ÂûãÂèÇÊï∞„ÄÇ
![NPU1ÂèçÂêë‰º†Ëæì](images/10pipeline22.png)

```
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def get_forward_backward_func():
  pipeline_model_parallel_size = parallel_state.get_pipeline_model_parallel_world_size()
    if pipeline_model_parallel_size > 1:
        if parallel_state.get_virtual_pipeline_model_parallel_world_size() is not None:
            forward_backward_func = forward_backward_pipelining_with_interleaving
        else:
            forward_backward_func = forward_backward_pipelining_without_interleaving
    else:
        forward_backward_func = forward_backward_no_pipelining
    return forward_backward_func


def forward_backward_pipelining_without_interleaving(...)
    def enable_grad_sync():
        output_tensor_grad = recv_backward(
                        send_tensor_shapes, config, parallel_state.is_pipeline_last_stage()
                    )

                    input_tensor_grad = backward_step(
                        input_tensor, output_tensor, output_tensor_grad, model_type, config
                    )

                    send_backward(
                        input_tensor_grad,
                        recv_tensor_shapes,
                        config,
                        parallel_state.is_pipeline_first_stage(),
                    )

                # Launch any remaining grad reductions.
                if no_sync_context is not None:
                    enable_grad_sync()
                    if config.grad_sync_func is not None:
                        config.grad_sync_func(model.parameters())

            if config.finalize_model_grads_func is not None and not forward_only:

                # If defer_embedding_wgrad_compute is enabled we need to do the
                # weight gradient GEMM's here.
                finish_embedding_wgrad_compute(config, embedding_module)

                # Finalize model grads (perform full grad all-reduce / reduce-scatter for
                # data parallelism, layernorm all-reduce for sequence parallelism, and
                # embedding all-reduce for pipeline parallelism).
                config.finalize_model_grads_func(
                    [model], total_num_tokens if config.calculate_per_token_loss else None
                )

            if config.timers is not None:
                config.timers('forward-backward').stop()

            if hasattr(config, 'enable_cuda_graph') and config.enable_cuda_graph:
                create_cudagraphs()

            return forward_data_store
```

## ÂèÇËÄÉÊñáÁåÆÔºö
https://zhuanlan.zhihu.com/p/650744349
https://zhuanlan.zhihu.com/p/701716465
https://blog.csdn.net/just_sort/article/details/135981391
https://blog.csdn.net/HaoBBNuanMM/article/details/134095326
https://github.com/NVIDIA/Megatron-LM