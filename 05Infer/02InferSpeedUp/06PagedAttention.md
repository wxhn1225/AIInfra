# Paged Attention 原理

## 大模型推理的内存管理挑战

大模型推理中，处理推理请求的数量受到 GPU 内存容量的限制，也就是说，推理服务系统的吞吐量是 memory-bound，克服这个内存限制需要解决以下内存管理方面的挑战：
1. KV Cache 内存大。KV Cache 的大小随着请求数量的增加而迅速增长，如图所示，KV Cache 所占内存接近大模型参数的一半。
2. 复杂的解码策略。大模型推理有多种解码策略，每种算法对内存管理的影响各不相同。
3. 输入与输出序列长度未知。在大模型推理中，输入 prompt 与最终输出长度是不确定的。


## Paged Attention 原理

### 操作系统虚拟内存概念

### Paged Attention 算法

### KV Cache 管理

### 不同解码策略下的表现


## 调度与抢占

## 分布式场景内存管理

## Attention 算子适配

## 小结与思考

## 本节视频